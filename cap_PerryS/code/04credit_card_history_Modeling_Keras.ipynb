{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit-Card Default Risk\n",
    "#### by Perry Shyr\n",
    "## _4-of-7. Modeling with Keras_\n",
    "![](../images/cards.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "\n",
    "### Credit-card lenders absorb significant losses from consumer defaults.  This capstone revolves around the detection of anomalies in customer demographic and borrowing history to identify credit-card default risk.  It is a binary classification problem with customers who default as the positive class, and unbalanced classes.  For supervised modeling, lenders are probably interested in not just the True-Positive (TP) rate, but also in the False-Negative (FN) and False-Positve (FP) rates. The best Estimator should minimize for both FN's and FP's while generalizing for TP's.\n",
    "\n",
    "## Executive Summary\n",
    "\n",
    "### Neural networks have been found to be the best estimators in the literature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Code Libraries Used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/perry/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras import regularizers\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Load Data from Notebook-3\n",
    "\n",
    "### In the previous notebook of this kernel-series, we added six new features to the cleaned and validated dataset from the first notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "accts_nf = pd.read_csv('../assets/credit_new_features.csv', index_col='ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'X' is the training set containing all the features without the dependent target variable, 'y.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = accts_nf.drop(['Oct_Default'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = accts_nf['Oct_Default']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Validation-splitting and Scaling\n",
    "\n",
    "### It is necessary to set stratify to ensure that the proportions of the classes present in folds match that in the original target-series.  Scaling is needed because some of the features have small ranges and the others have very large ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    stratify=y,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "\n",
    "X_train_sc = ss.fit_transform(X_train)\n",
    "X_test_sc = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7492, 35)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_test_sc.shape)\n",
    "type(X_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>credit_limit</th>\n",
       "      <th>gender</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>...</th>\n",
       "      <th>leverage_3</th>\n",
       "      <th>leverage_4</th>\n",
       "      <th>leverage_5</th>\n",
       "      <th>leverage_6</th>\n",
       "      <th>bill_to_pay1</th>\n",
       "      <th>bill_to_pay2</th>\n",
       "      <th>bill_to_pay3</th>\n",
       "      <th>bill_to_pay4</th>\n",
       "      <th>bill_to_pay5</th>\n",
       "      <th>bill_to_pay6</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7362</th>\n",
       "      <td>150000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.956587</td>\n",
       "      <td>0.949460</td>\n",
       "      <td>0.967333</td>\n",
       "      <td>1.021527</td>\n",
       "      <td>27.251087</td>\n",
       "      <td>29.048462</td>\n",
       "      <td>28.134902</td>\n",
       "      <td>26.871509</td>\n",
       "      <td>13.311927</td>\n",
       "      <td>319999.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12267</th>\n",
       "      <td>290000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001366</td>\n",
       "      <td>0.001366</td>\n",
       "      <td>0.001366</td>\n",
       "      <td>0.001366</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29379</th>\n",
       "      <td>290000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030038</td>\n",
       "      <td>0.032445</td>\n",
       "      <td>0.035010</td>\n",
       "      <td>0.033952</td>\n",
       "      <td>5.329167</td>\n",
       "      <td>4.886667</td>\n",
       "      <td>8.711000</td>\n",
       "      <td>10.454444</td>\n",
       "      <td>319999.000000</td>\n",
       "      <td>12.3075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24609</th>\n",
       "      <td>360000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000733</td>\n",
       "      <td>0.006092</td>\n",
       "      <td>0.001467</td>\n",
       "      <td>0.000733</td>\n",
       "      <td>0.231782</td>\n",
       "      <td>319999.000000</td>\n",
       "      <td>0.120383</td>\n",
       "      <td>4.153409</td>\n",
       "      <td>319999.000000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14979</th>\n",
       "      <td>480000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003665</td>\n",
       "      <td>0.003665</td>\n",
       "      <td>0.003665</td>\n",
       "      <td>0.003665</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       credit_limit  gender  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  \\\n",
       "ID                                                                           \n",
       "7362         150000       2          1         2   30      0      0      0   \n",
       "12267        290000       2          3         2   37     -1     -1     -1   \n",
       "29379        290000       1          1         2   28      0      0      0   \n",
       "24609        360000       1          1         1   39     -1     -1      2   \n",
       "14979        480000       2          2         2   31     -1     -1     -1   \n",
       "\n",
       "       PAY_4  PAY_5      ...       leverage_3  leverage_4  leverage_5  \\\n",
       "ID                       ...                                            \n",
       "7362       0      0      ...         0.956587    0.949460    0.967333   \n",
       "12267     -1     -1      ...         0.001366    0.001366    0.001366   \n",
       "29379      2      2      ...         0.030038    0.032445    0.035010   \n",
       "24609     -1     -1      ...         0.000733    0.006092    0.001467   \n",
       "14979     -1     -1      ...         0.003665    0.003665    0.003665   \n",
       "\n",
       "       leverage_6  bill_to_pay1   bill_to_pay2  bill_to_pay3  bill_to_pay4  \\\n",
       "ID                                                                           \n",
       "7362     1.021527     27.251087      29.048462     28.134902     26.871509   \n",
       "12267    0.001366      1.000000       1.000000      1.000000      1.000000   \n",
       "29379    0.033952      5.329167       4.886667      8.711000     10.454444   \n",
       "24609    0.000733      0.231782  319999.000000      0.120383      4.153409   \n",
       "14979    0.003665      1.000000       1.000000      1.000000      1.000000   \n",
       "\n",
       "        bill_to_pay5  bill_to_pay6  \n",
       "ID                                  \n",
       "7362       13.311927   319999.0000  \n",
       "12267       1.000000        1.0000  \n",
       "29379  319999.000000       12.3075  \n",
       "24609  319999.000000        1.0000  \n",
       "14979       1.000000        1.0000  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D. First Model\n",
    "\n",
    "### The artificial neural network approach of Keras running TensorFlow in the back end was chosen for initial testing based largely on the original academic [publication](https://bradzzz.gitbooks.io/ga-seattle-dsi/content/dsi/dsi_05_classification_databases/2.1-lesson/assets/datasets/DefaultCreditCardClients_yeh_2009.pdf) that introduced the original dataset in 2009.  In that paper, their neural-network model performed the best on a variation of an AOC-related metric.\n",
    "\n",
    "### In this notebook, a wide set of hyperparameters was tested manually including:\n",
    "#### -topologic (number of neurons, number of hidden layers)\n",
    "#### -features (original set of 23 features and a later set with 12 interaction features)\n",
    "#### -epochs\n",
    "#### -batch-size (based a [blog](https://blogs.oracle.com/meena/simple-neural-network-model-using-keras-and-grid-search-hyperparameterstuning) from a literature search)\n",
    "#### -all available optimizers\n",
    "#### (James Hampton of GA suggested creating a custom loss-function to minimize for either the False-negative or False-positive rates, but we could not find an online example for making one work)\n",
    "\n",
    "### The rationale for performing the manual tuning came from relatively few number of epochs needed for convergence and eventual overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(35, activation='relu', input_dim=X.shape[1]))\n",
    "model.add(Dense(35, activation='relu', input_dim=X.shape[1]))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid')) # always have 1 neuron, with no activation function\n",
    "\n",
    "model.compile(loss='logcosh', optimizer='adam', metrics=['accuracy'])\n",
    "results = model.fit(X_train_sc, y_train,\n",
    "                    validation_data=(X_test_sc, y_test), verbose=0,\n",
    "                    epochs=32, batch_size=320)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The main observation is that not many epochs are needed before convergence and eventual overfitting takes place.  Possibly as few as 9 epochs are needed to see a bottoming of test losses (and topping of test-accuracies). \n",
    "\n",
    "### Let's plot the progression of loss reduction through the specified number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a44c982b0>"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results.history.keys()\n",
    "\n",
    "plt.plot(results.history['val_loss'], label='Test Loss')\n",
    "plt.plot(results.history['loss'], label='Train Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can see that with 12 additional features added to the feature-set, the model has started to show overfitting.  From the manual testing, I don't see evidence that adding the extra interaction terms hurts the modeling, so perhaps any collinearity is not having a negative effect.\n",
    "\n",
    "### With \"verbose=1\" we can see that the measure of accuracy reaches about 0.82.  Unfortunately, due to lenders' intent for customer retention, they will invariably want to manage their risk exposure from False-negatives.  From a customer service standpoint, they also want to minimize False-positives, so it becomes a balancing act, walking the fine line between disparate commercial interests.  Customers want to feel valued, and business want to curb losses from default.\n",
    "\n",
    "### Just out of curiosity, let's calculate the percentage difference between our baseline model from Notebook-2 and our current result of 0.82."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage lift above baseline of 77.9% is: 0.05285208913649029\n"
     ]
    }
   ],
   "source": [
    "baseline = 1-(y.sum()/len(y))\n",
    "print('percentage lift above baseline of 77.9% is:',(0.8199-(baseline))/baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There is only a slim margin of separation, probably not enough to be worth reporting.  A 10% lift would be more impressive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E. Save the model, splits and scaling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../assets/model_keras.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.to_csv('../assets/X_processed.csv', index=True)\n",
    "y.to_csv('../assets/y_target.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv('../assets/X_train_split.csv')\n",
    "X_test.to_csv('../assets/X_test_split.csv')\n",
    "y_train.to_csv('../assets/y_train_split.csv')\n",
    "y_test.to_csv('../assets/y_test_split.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"../assets/X_train_scaled.csv\", X_train_sc, delimiter=\",\")\n",
    "np.savetxt(\"../assets/X_test_scaled.csv\", X_test_sc, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's add the code to save the the split data separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.to_csv('../assets/X_new_features.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv('../assets/X_train_split_nf.csv')\n",
    "X_test.to_csv('../assets/X_test_split_nf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"../assets/X_train_scaled_nf.csv\", X_train_sc, delimiter=\",\")\n",
    "np.savetxt(\"../assets/X_test_scaled_nf.csv\", X_test_sc, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continue to Notebook-5, Model Building, Part-2.\n",
    "\n",
    "### A serious effort was made to target False-Negatives and/or False-Positives optimization.  I learned that adjusting the 'metrics=' input (which I tried) has no effect on any back-propagation process, but serves only to inform the user for reporting purposes.  Also, any gradient descent activity is superfluous because it is already built into the optimization process.\n",
    "\n",
    "### I was told about possibly using weights to penalize misclassification and about building a custom loss function connected to the backend built on TensorFlow, but I thought I only had time to try a custom loss function based on the formulae for False-Negative and False-Positive rates.  There wasn't an online discussion that I or James Hampton could find to accomplish this.\n",
    "\n",
    "### I did try the various other available loss functions and found Mean_Squared_Logarithmic_Errors(MSLE)-loss as optimized for penalizing False-Positives, while Logcosh-loss seemed to act in the same way for penalizing False-Negatives.  Based on this manual work.  I would consider the Logcosh-loss function to be the best performing in terms minimizing False-Negatives and maximizing True-positives.  Binary_crossentropy-loss would be a close second-best performer and MSLE the third-best because it does not lift True-Positives. \n",
    "\n",
    "### For the next notebook, I would like to show some Grid-searching and a separate TensorFlow neural-network.  That notebook will be followed by more basic/interpretable classification models.\n",
    "\n",
    "### Finally, in the last notebook I will evaluate all five models for misclassification and inference on the best estimator and best predictors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
