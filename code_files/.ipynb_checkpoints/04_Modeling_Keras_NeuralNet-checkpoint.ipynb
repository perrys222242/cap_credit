{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit-Card Default Risk\n",
    "by Perry Shyr\n",
    "## _4-of-7. Modeling with Keras_\n",
    "![](../image_files/cards.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "\n",
    "Given a dataset with demographic and borrowing history data for accounts classified as defaulting or not defaulting in October-2005, can I build a supervised model that performs better than identifying only members of the negative non-default class (baseline model) while minimizing the misclassification of either class?  In the context of credit-card lending, if I can predict accounts as belonging to the defaulting class, I want to minimize the number of predicted defaulters who did not actually default that October (lost revenues) while minimizing the number of predicted non-defaulters who did end up defaulting (lost profits).\n",
    "\n",
    "## Preamble for Modeling-Keras Notebook\n",
    "\n",
    "In this notebook, I split and scale the data and save the transformed results.  I use the scaled results for the neural-networks modeling to run several manual tests to optimize hyperparameters including batch_size and optimizer.  I also test a number of different network topologies (number of neurons and hidden layers).  The testing below does not include attempts to build a custom loss-function based on the False-negative and False-positive rate formulae, but are kept in mind for continued attempts as next steps.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Code Libraries Used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/perry/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras import regularizers\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Load Data from Notebook-3\n",
    "\n",
    "In the previous notebook of this kernel-series, we added six new features to the cleaned and validated dataset from the first notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "accts_nf = pd.read_csv('../asset_files/credit_new_features.csv', index_col='ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'X' is the training set containing all the features without the dependent target variable, 'y.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = accts_nf.drop(['Oct_Default'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = accts_nf['Oct_Default']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Validation-splitting and Scaling\n",
    "\n",
    "It is necessary to set stratify to ensure that the proportions of the classes present in folds match that in the original target-series.  Scaling is needed because some of the features have small ranges and the others have very large ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    stratify=y,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "\n",
    "X_train_sc = ss.fit_transform(X_train)\n",
    "X_test_sc = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7492, 42)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_test_sc.shape)\n",
    "type(X_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>credit_limit</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>PAY_6</th>\n",
       "      <th>BILL_AMT1</th>\n",
       "      <th>BILL_AMT2</th>\n",
       "      <th>...</th>\n",
       "      <th>gender_m</th>\n",
       "      <th>gender_f</th>\n",
       "      <th>edu_grad_schl</th>\n",
       "      <th>edu_college</th>\n",
       "      <th>edu_high_schl</th>\n",
       "      <th>edu_other</th>\n",
       "      <th>marital_mrrd</th>\n",
       "      <th>marital_sngl</th>\n",
       "      <th>marital_dvcd</th>\n",
       "      <th>marital_othr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7362</th>\n",
       "      <td>150000</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>150426</td>\n",
       "      <td>151052</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12267</th>\n",
       "      <td>290000</td>\n",
       "      <td>37</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>396</td>\n",
       "      <td>396</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29379</th>\n",
       "      <td>290000</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6395</td>\n",
       "      <td>7330</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24609</th>\n",
       "      <td>360000</td>\n",
       "      <td>39</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>264</td>\n",
       "      <td>1139</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14979</th>\n",
       "      <td>480000</td>\n",
       "      <td>31</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1759</td>\n",
       "      <td>1759</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       credit_limit  AGE  PAY_0  PAY_2  PAY_3  PAY_4  PAY_5  PAY_6  BILL_AMT1  \\\n",
       "ID                                                                              \n",
       "7362         150000   30      0      0      0      0      0      0     150426   \n",
       "12267        290000   37     -1     -1     -1     -1     -1     -1        396   \n",
       "29379        290000   28      0      0      0      2      2      2       6395   \n",
       "24609        360000   39     -1     -1      2     -1     -1      0        264   \n",
       "14979        480000   31     -1     -1     -1     -1     -1     -1       1759   \n",
       "\n",
       "       BILL_AMT2      ...       gender_m  gender_f  edu_grad_schl  \\\n",
       "ID                    ...                                           \n",
       "7362      151052      ...              0         1              1   \n",
       "12267        396      ...              0         1              0   \n",
       "29379       7330      ...              1         0              1   \n",
       "24609       1139      ...              1         0              1   \n",
       "14979       1759      ...              0         1              0   \n",
       "\n",
       "       edu_college  edu_high_schl  edu_other  marital_mrrd  marital_sngl  \\\n",
       "ID                                                                         \n",
       "7362             0              0          0             0             1   \n",
       "12267            0              1          0             0             1   \n",
       "29379            0              0          0             0             1   \n",
       "24609            0              0          0             1             0   \n",
       "14979            1              0          0             0             1   \n",
       "\n",
       "       marital_dvcd  marital_othr  \n",
       "ID                                 \n",
       "7362              0             0  \n",
       "12267             0             0  \n",
       "29379             0             0  \n",
       "24609             0             0  \n",
       "14979             0             0  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D. First Model\n",
    "\n",
    "The artificial neural network approach of Keras running TensorFlow in the back end was chosen for initial testing based largely on the original academic [publication](https://bradzzz.gitbooks.io/ga-seattle-dsi/content/dsi/dsi_05_classification_databases/2.1-lesson/assets/datasets/DefaultCreditCardClients_yeh_2009.pdf) that introduced the original dataset in 2009.  In that paper, their neural-network model performed the best on a variation of an AOC-related metric.\n",
    "\n",
    "In this notebook, a wide set of hyperparameters was tested manually including: \n",
    "\n",
    "-topologic (number of neurons, number of hidden layers)\n",
    "\n",
    "-features (original set of 23 features and a later set with 12 interaction features)\n",
    "\n",
    "-epochs\n",
    "\n",
    "-batch-size (based a [blog](https://blogs.oracle.com/meena/simple-neural-network-model-using-keras-and-grid-search-hyperparameterstuning) from a literature search)\n",
    "\n",
    "-all available optimizers\n",
    "\n",
    "(James Hampton of GA suggested creating a custom loss-function to minimize for either the False-negative or False-positive rates, but we could not find an online example for making one work)\n",
    "\n",
    "The rationale for performing the manual tuning came from relatively few number of epochs needed for convergence and eventual overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22473 samples, validate on 7492 samples\n",
      "Epoch 1/20\n",
      "22473/22473 [==============================] - 0s 19us/step - loss: 0.0867 - acc: 0.7532 - val_loss: 0.0725 - val_acc: 0.7895\n",
      "Epoch 2/20\n",
      "22473/22473 [==============================] - 0s 5us/step - loss: 0.0734 - acc: 0.7950 - val_loss: 0.0682 - val_acc: 0.8085\n",
      "Epoch 3/20\n",
      "22473/22473 [==============================] - 0s 5us/step - loss: 0.0696 - acc: 0.8070 - val_loss: 0.0668 - val_acc: 0.8110\n",
      "Epoch 4/20\n",
      "22473/22473 [==============================] - 0s 5us/step - loss: 0.0677 - acc: 0.8104 - val_loss: 0.0660 - val_acc: 0.8146\n",
      "Epoch 5/20\n",
      "22473/22473 [==============================] - 0s 5us/step - loss: 0.0668 - acc: 0.8140 - val_loss: 0.0656 - val_acc: 0.8142\n",
      "Epoch 6/20\n",
      "22473/22473 [==============================] - 0s 5us/step - loss: 0.0663 - acc: 0.8136 - val_loss: 0.0653 - val_acc: 0.8153\n",
      "Epoch 7/20\n",
      "22473/22473 [==============================] - 0s 5us/step - loss: 0.0658 - acc: 0.8157 - val_loss: 0.0649 - val_acc: 0.8166\n",
      "Epoch 8/20\n",
      "22473/22473 [==============================] - 0s 5us/step - loss: 0.0655 - acc: 0.8163 - val_loss: 0.0648 - val_acc: 0.8154\n",
      "Epoch 9/20\n",
      "22473/22473 [==============================] - 0s 6us/step - loss: 0.0650 - acc: 0.8187 - val_loss: 0.0648 - val_acc: 0.8155\n",
      "Epoch 10/20\n",
      "22473/22473 [==============================] - 0s 9us/step - loss: 0.0645 - acc: 0.8195 - val_loss: 0.0645 - val_acc: 0.8166\n",
      "Epoch 11/20\n",
      "22473/22473 [==============================] - 0s 6us/step - loss: 0.0645 - acc: 0.8177 - val_loss: 0.0642 - val_acc: 0.8166\n",
      "Epoch 12/20\n",
      "22473/22473 [==============================] - 0s 6us/step - loss: 0.0642 - acc: 0.8192 - val_loss: 0.0641 - val_acc: 0.8170\n",
      "Epoch 13/20\n",
      "22473/22473 [==============================] - 0s 6us/step - loss: 0.0640 - acc: 0.8191 - val_loss: 0.0641 - val_acc: 0.8169\n",
      "Epoch 14/20\n",
      "22473/22473 [==============================] - 0s 7us/step - loss: 0.0637 - acc: 0.8209 - val_loss: 0.0639 - val_acc: 0.8179\n",
      "Epoch 15/20\n",
      "22473/22473 [==============================] - 0s 6us/step - loss: 0.0637 - acc: 0.8203 - val_loss: 0.0638 - val_acc: 0.8179\n",
      "Epoch 16/20\n",
      "22473/22473 [==============================] - 0s 6us/step - loss: 0.0633 - acc: 0.8213 - val_loss: 0.0639 - val_acc: 0.8175\n",
      "Epoch 17/20\n",
      "22473/22473 [==============================] - 0s 7us/step - loss: 0.0633 - acc: 0.8220 - val_loss: 0.0637 - val_acc: 0.8166\n",
      "Epoch 18/20\n",
      "22473/22473 [==============================] - 0s 6us/step - loss: 0.0634 - acc: 0.8212 - val_loss: 0.0636 - val_acc: 0.8186\n",
      "Epoch 19/20\n",
      "22473/22473 [==============================] - 0s 6us/step - loss: 0.0631 - acc: 0.8226 - val_loss: 0.0635 - val_acc: 0.8179\n",
      "Epoch 20/20\n",
      "22473/22473 [==============================] - 0s 5us/step - loss: 0.0627 - acc: 0.8229 - val_loss: 0.0634 - val_acc: 0.8175\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(42, activation='relu', input_dim=X.shape[1]))\n",
    "model.add(Dense(42, activation='relu', input_dim=X.shape[1]))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid')) # always have 1 neuron, with no activation function\n",
    "\n",
    "model.compile(loss='logcosh', optimizer='adam', metrics=['accuracy'])\n",
    "results = model.fit(X_train_sc, y_train,\n",
    "                    validation_data=(X_test_sc, y_test), verbose=1,\n",
    "                    epochs=20, batch_size=320)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main observation is that not many epochs are needed before convergence and eventual overfitting takes place.  With test accuracies almost reaching 82%, we cannot say that this model performs better than the baseline model. \n",
    "\n",
    "Let's plot the progression of loss reduction through the specified number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a22e29d30>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results.history.keys()\n",
    "\n",
    "plt.plot(results.history['val_loss'], label='Test Loss')\n",
    "plt.plot(results.history['loss'], label='Train Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that with 12 additional features added to the feature-set, the model has started to show overfitting.  From the manual testing, I don't see evidence that adding the extra interaction terms hurts the modeling, so perhaps any collinearity is not having a negative effect.\n",
    "\n",
    "With \"verbose=1\" we can see that the measure of accuracy reaches about 0.82.  Unfortunately, due to lenders' intent for customer retention, they will invariably want to manage their risk exposure from False-negatives.  From a customer service standpoint, they also want to minimize False-positives, so it becomes a balancing act, walking the fine line between disparate commercial interests.  Customers want to feel valued, and business want to curb losses from default.\n",
    "\n",
    "Just out of curiosity, let's calculate the percentage difference between our baseline model from Notebook-2 and our current result of 0.82."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage lift above baseline of 77.9% is: 0.0502838440111421\n"
     ]
    }
   ],
   "source": [
    "baseline = 1-(y.sum()/len(y))\n",
    "print('percentage lift above baseline of 77.9% is:',(0.8179-(baseline))/baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is only a slim margin of separation, probably not enough to be worth reporting.  A 10% lift would be meaningful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E. Save the model, splits and scaling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../asset_files/model_keras.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.to_csv('../asset_files/X_processed.csv', index=True)\n",
    "y.to_csv('../asset_files/y_target.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv('../asset_files/X_train_split.csv')\n",
    "X_test.to_csv('../asset_files/X_test_split.csv')\n",
    "y_train.to_csv('../asset_files/y_train_split.csv')\n",
    "y_test.to_csv('../asset_files/y_test_split.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"../asset_files/X_train_scaled.csv\", X_train_sc, delimiter=\",\")\n",
    "np.savetxt(\"../asset_files/X_test_scaled.csv\", X_test_sc, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continue to Notebook-5, Model Building, Part-2.\n",
    "\n",
    "A serious effort was made to target False-Negatives and/or False-Positives optimization.  I learned that adjusting the 'metrics=' input (which I tried) has no effect on any back-propagation process, but serves only to inform the user for reporting purposes.  Also, any gradient descent activity is superfluous because it is already built into the optimization process.\n",
    "\n",
    "I was told about possibly using weights to penalize misclassification and about building a custom loss function connected to the backend built on TensorFlow, but I thought I only had time to try a custom loss function based on the formulae for False-Negative and False-Positive rates.  There wasn't an online discussion that I or James Hampton could find to accomplish this.\n",
    "\n",
    "I did try the various other available loss functions and found Mean_Squared_Logarithmic_Errors(MSLE)-loss as optimized for penalizing False-Positives, while Logcosh-loss seemed to act in the same way for penalizing False-Negatives.  Based on this manual work.  I would consider the Logcosh-loss function to be the best performing in terms minimizing False-Negatives and maximizing True-positives.  Binary_crossentropy-loss would be a close second-best performer and MSLE the third-best because it does not lift True-Positives. \n",
    "\n",
    "For the next notebook, I would like to show some Grid-searching and a separate TensorFlow neural-network.  That notebook will be followed by more basic/interpretable classification models.\n",
    "\n",
    "Finally, in the last notebook I will evaluate all five models for misclassification and inference on the best estimator and best predictors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
